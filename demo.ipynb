{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import DATA_PATH\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "TWITTER16= 'twitter16'\n",
    "TWITTER15= 'twitter15'\n",
    "PHEME = 'pheme'\n",
    "RUMOUREVAL= 'rumoureval'\n",
    "POLITIFACT= 'politifact'\n",
    "GOSSIPCOP= 'gossipcop'\n",
    "HASOC= 'hasoc'\n",
    "POLITIFACT= 'politifact'\n",
    "FIGLANG_TWITTER= 'figlang_twitter'\n",
    "FIGLANG_REDDIT= 'figlang_reddit'\n",
    "ANTIVAX= 'antivax'\n",
    "model_ckt = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawFakeNewsDataset(Dataset):\n",
    "    def __init__(self, path, model_ckt, max_comments=None, max_length_sentences=None):\n",
    "        super(RawFakeNewsDataset, self).__init__()\n",
    "        self.df = pd.read_csv(path)\n",
    "        self.df['comments'] = self.df['comments'].map(lambda x: x.split('::'), na_action='ignore')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_ckt) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def collate_fn(self, samples):\n",
    "        \"\"\"Here, samples will be the sample returned by __getitem__ function\"\"\"\n",
    "        print(samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.df.iloc[index] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = POLITIFACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unproven vaccine? Wtf? SOMETHING!!!\n"
     ]
    }
   ],
   "source": [
    "path = f'{DATA_PATH}/data/{dataset}/{dataset}.csv'\n",
    "ds = RawFakeNewsDataset(path, model_ckt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10K THB for an unlicensed, largely untested vaccine with an efficacy rate statistically below your own immune systeâ€¦ https://t.co/vQYhSkv8xw'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[6]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                  antivax_6\n",
       "text        10K THB for an unlicensed, largely untested va...\n",
       "comments    [THB for admin. and a nurse to give the jab? T...\n",
       "labels                                                      1\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THB for admin. and a nurse to give the jab? They really know how to take the piss.However, as is often the case here, the \"misunderstanding\" gambit is rolled out on cue to save face.',\n",
       " 'A perfect example of fear factor from the constant media coverage.']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[6]['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3797"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "       model_inference        60.69%     159.000us       100.00%     262.000us     262.000us             1  \n",
      "          aten::linear         3.44%       9.000us        39.31%     103.000us     103.000us             1  \n",
      "               aten::t         8.40%      22.000us        14.12%      37.000us      37.000us             1  \n",
      "       aten::transpose         4.58%      12.000us         5.73%      15.000us      15.000us             1  \n",
      "      aten::as_strided         1.53%       4.000us         1.53%       4.000us       2.000us             2  \n",
      "           aten::addmm        16.03%      42.000us        21.76%      57.000us      57.000us             1  \n",
      "          aten::expand         1.91%       5.000us         2.29%       6.000us       6.000us             1  \n",
      "           aten::copy_         3.44%       9.000us         3.44%       9.000us       9.000us             1  \n",
      "    aten::resolve_conj         0.00%       0.000us         0.00%       0.000us       0.000us             2  \n",
      "----------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 262.000us\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-07-07 16:29:52 1785616:1785616 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-07-07 16:29:52 1785616:1785616 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-07-07 16:29:52 1785616:1785616 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import profiler\n",
    "\n",
    "# Define your PyTorch model\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc = torch.nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Create an instance of your model\n",
    "model = MyModel()\n",
    "\n",
    "# Create some input data\n",
    "input_data = torch.randn(100, 10)\n",
    "\n",
    "# Enable profiling\n",
    "with profiler.profile(record_shapes=True) as prof:\n",
    "    with profiler.record_function(\"model_inference\"):\n",
    "        # Perform model inference\n",
    "        output = model(input_data)\n",
    "\n",
    "# Print the profiling results\n",
    "print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
