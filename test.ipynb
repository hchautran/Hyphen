{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "def benchmark_throughput(model, input_size, num_iterations=100):\n",
    "    # Create random input tensor\n",
    "    input_tensor = torch.randn(*input_size)\n",
    "\n",
    "    # Move model and input tensor to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    # Warm-up run\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    # Start benchmarking\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        with torch.no_grad():\n",
    "            model(input_tensor)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate throughput\n",
    "    elapsed_time = end_time - start_time\n",
    "    throughput = num_iterations / elapsed_time\n",
    "\n",
    "    return throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from const import (\n",
    "   ANTIVAX,\n",
    "   TWITTER16,\n",
    "   TWITTER15,\n",
    "   PHEME,\n",
    "   FIGLANG_TWITTER,\n",
    "   POLITIFACT,\n",
    ") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "lorentz\n",
      "0.617 & 0.561 & 0.544 & 35.76\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# dataset = TWITTER16 \n",
    "# dataset = TWITTER15 \n",
    "dataset = PHEME \n",
    "# dataset = FIGLANG_TWITTER\n",
    "# dataset = POLITIFACT\n",
    "# dataset = ANTIVAX\n",
    "\n",
    "df = pd.read_csv(f'results/{dataset}.csv')\n",
    "hs4_df = df.loc[df['model'] == 'hs4']\n",
    "bert_df = df.loc[df['model'] == 'bert']\n",
    "han_df = df.loc[df['model'] == 'han']\n",
    "hyphen_df = df.loc[df['model'] == 'hyphen']\n",
    "df =bert_df \n",
    "for i in range(0, len(df)):\n",
    "   model = df.iloc[i]['model']\n",
    "   manifold = df.iloc[i]['manifold']\n",
    "   fourier = df.iloc[i]['fourier']\n",
    "   f1 = df.iloc[i]['f1']\n",
    "   prec = df.iloc[i]['prec']\n",
    "   rec = df.iloc[i]['rec']\n",
    "   train_time = df.iloc[i]['train time']\n",
    "   print(fourier) \n",
    "   print(manifold)\n",
    "   print(f'{prec:.3f} & {rec:.3f} & {f1:.3f} & {train_time:.2f}')\n",
    "   print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Initialize wandb and retrieve data\n",
    "api = wandb.Api()\n",
    "entity, project = 'eddiechen372', dataset \n",
    "runs = api.runs(f\"{entity}/{project}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# for run in tqdm(runs):\n",
    "#    run = api.run(f\"{entity}/{project}/{run.id}\")\n",
    "#    config = run.config\n",
    "#    history = run.scan_history(keys=['best F1', 'epoch'])\n",
    "#    type = config['type']\n",
    "#    manifold = config['manifold']\n",
    "#    for i,row in enumerate(history):\n",
    "#       row = pd.DataFrame({'type': [type], 'manifold': [manifold], 'epoch': [row['epoch']], 'best F1': [row['best F1']]})\n",
    "#       df = pd.concat([df, row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['type'] == 'hs4']\n",
    "# sns.set_theme(style=\"darkgrid\")\n",
    "# sns.lineplot(data=df, x=\"epoch\", y=\"best F1\", hue=\"manifold\", style=\"manifold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-iec_chau/miniconda3/envs/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jupyter-iec_chau/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/jupyter-iec_chau/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/jupyter-iec_chau/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n",
      "/home/jupyter-iec_chau/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from const import (\n",
    "   LORENTZ, \n",
    "   POINCARE, \n",
    "   EUCLID, \n",
    "   HAN, \n",
    "   HYPHEN, \n",
    "   HS4, \n",
    "   BERT,\n",
    "   TWITTER16,\n",
    "   TWITTER15, \n",
    "   PHEME,\n",
    "   POLITIFACT,\n",
    "   FIGLANG_TWITTER,\n",
    "   ANTIVAX,\n",
    ")\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from trainer import Trainer \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using manifold  euclid\n",
      "using fourier False\n",
      "using manifold  poincare\n",
      "using fourier False\n",
      "using manifold  euclid\n",
      "using fourier False\n",
      "saved tokenizer\n",
      "Building model....\n",
      "building HypPostEnc\n",
      "building HypComEnc\n",
      "building CoAttention\n",
      "han built\n",
      "saved tokenizer\n",
      "Building model....\n",
      "building HypPostEnc\n",
      "building HypComEnc\n",
      "building CoAttention\n",
      "bert built\n",
      "saved tokenizer\n",
      "Building model....\n",
      "building HypPostEnc\n",
      "building HypComEnc\n",
      "building CoAttention\n",
      "hs4 built\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from const import (DATA_PATH)\n",
    "import pickle\n",
    "file = open(f'{DATA_PATH}/data/{dataset}/{dataset}_preprocessed.pkl', 'rb')\n",
    "df = pd.read_csv(f'data/{dataset}/{dataset}.csv') \n",
    "props = pickle.load(file)\n",
    "\n",
    "id_train, id_test = props['train']['id'], props['val']['id']\n",
    "raw_c_train, raw_c_val = list(df[df['id'].isin(id_train)]['comments']), list(df[df['id'].isin(id_test)]['comments'])\n",
    "raw_c_train = [c.split('::') if isinstance(c, str) else '' for c in raw_c_train]\n",
    "raw_c_val= [c.split('::') if isinstance(c, str) else '' for c in raw_c_val]\n",
    "x_train, x_val = props['train']['x'], props['val']['x']\n",
    "y_train, y_val = props['train']['y'], props['val']['y']\n",
    "c_train, c_val = props['train']['c'], props['val']['c']\n",
    "sub_train, sub_val = props['train']['subgraphs'], props['val']['subgraphs']\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' \n",
    "hs4_trainer = Trainer(\n",
    "    manifold=EUCLID,\n",
    "    model_type=HS4,\n",
    "    platform=TWITTER16, \n",
    "    max_sen_len=30, \n",
    "    max_com_len=30, \n",
    "    max_sents=20, \n",
    "    max_coms=20, \n",
    "    lr = 1e-3, \n",
    "    fourier = False,\n",
    "    curv=1.0,\n",
    "    enable_log=False,\n",
    "    embedding_dim=200\n",
    ")\n",
    "bert_trainer = Trainer(\n",
    "    manifold=POINCARE,\n",
    "    model_type=BERT,\n",
    "    platform=EUCLID, \n",
    "    max_sen_len=30, \n",
    "    max_com_len=30, \n",
    "    max_sents=20, \n",
    "    max_coms=20, \n",
    "    lr = 1e-3, \n",
    "    fourier = False,\n",
    "    curv=1.0,\n",
    "    enable_log=False,\n",
    "    embedding_dim=200\n",
    ")\n",
    "rnn_trainer = Trainer(\n",
    "    manifold=EUCLID,\n",
    "    model_type=HAN,\n",
    "    platform=TWITTER16, \n",
    "    max_sen_len=30, \n",
    "    max_com_len=30, \n",
    "    max_sents=20, \n",
    "    max_coms=20, \n",
    "    lr = 1e-3, \n",
    "    fourier = False,\n",
    "    curv=1.0,\n",
    "    enable_log=False,\n",
    "    embedding_dim=200\n",
    ")\n",
    "\n",
    "rnn_trainer.build_model(32)\n",
    "bert_trainer.build_model(32)\n",
    "hs4_trainer.build_model(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 42184061\n",
      "Total parameters: 13188060\n",
      "Total parameters: 12604460\n"
     ]
    }
   ],
   "source": [
    "bert= bert_trainer.model\n",
    "han = rnn_trainer.model\n",
    "hs4= hs4_trainer.model\n",
    "total_params = sum(p.numel() for p in bert.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "total_params = sum(p.numel() for p in han.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "total_params = sum(p.numel() for p in hs4.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:50<05:32,  4.16s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "# Assume model is already defined\n",
    "\n",
    "def measure_memory_footprint(model, comment_input_size, content_input_size):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    # Measure memory before inference\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.randint(0, 100, size=comment_input_size).to(device)\n",
    "        model(content=input_tensor, comment=input_tensor)\n",
    "    \n",
    "    # Measure memory after inference\n",
    "    memory_footprint = torch.cuda.max_memory_allocated(device) / (1024 ** 2)  # Convert to MB\n",
    "    return memory_footprint\n",
    "\n",
    "sequence_lengths = range(10, 10000, 100)  # Example: from 10 to 100 with a step of 10\n",
    "\n",
    "for i, model in enumerate([han, hs4, bert]):\n",
    "    memory_footprints = []\n",
    "    for seq_len in tqdm(sequence_lengths):\n",
    "        input_size = (32, seq_len, 10)  # Example input size, adjust based on your model\n",
    "        footprint = measure_memory_footprint(model, input_size, input_size)\n",
    "        memory_footprints.append(footprint)\n",
    "\n",
    "    plt.plot(sequence_lengths, memory_footprints )\n",
    "    plt.xlabel('Sequence Length')\n",
    "    plt.ylabel('Memory Footprint (MB)')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.legend(['han', 'hs4', 'msa'])\n",
    "plt.title('Model Memory Footprint vs. Sequence Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
