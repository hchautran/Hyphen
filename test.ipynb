{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "def benchmark_throughput(model, input_size, num_iterations=100):\n",
    "    # Create random input tensor\n",
    "    input_tensor = torch.randn(*input_size)\n",
    "\n",
    "    # Move model and input tensor to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    # Warm-up run\n",
    "    with torch.no_grad():\n",
    "        model(input_tensor)\n",
    "\n",
    "    # Start benchmarking\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        with torch.no_grad():\n",
    "            model(input_tensor)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate throughput\n",
    "    elapsed_time = end_time - start_time\n",
    "    throughput = num_iterations / elapsed_time\n",
    "\n",
    "    return throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from const import (\n",
    "   ANTIVAX,\n",
    "   TWITTER16,\n",
    "   TWITTER15,\n",
    "   PHEME,\n",
    "   FIGLANG_TWITTER,\n",
    "   POLITIFACT,\n",
    ") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "lorentz\n",
      "0.617 & 0.561 & 0.544 & 35.76\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# dataset = TWITTER16 \n",
    "# dataset = TWITTER15 \n",
    "dataset = PHEME \n",
    "# dataset = FIGLANG_TWITTER\n",
    "# dataset = POLITIFACT\n",
    "# dataset = ANTIVAX\n",
    "\n",
    "df = pd.read_csv(f'results/{dataset}.csv')\n",
    "hs4_df = df.loc[df['model'] == 'hs4']\n",
    "bert_df = df.loc[df['model'] == 'bert']\n",
    "han_df = df.loc[df['model'] == 'han']\n",
    "hyphen_df = df.loc[df['model'] == 'hyphen']\n",
    "df =bert_df \n",
    "for i in range(0, len(df)):\n",
    "   model = df.iloc[i]['model']\n",
    "   manifold = df.iloc[i]['manifold']\n",
    "   fourier = df.iloc[i]['fourier']\n",
    "   f1 = df.iloc[i]['f1']\n",
    "   prec = df.iloc[i]['prec']\n",
    "   rec = df.iloc[i]['rec']\n",
    "   train_time = df.iloc[i]['train time']\n",
    "   print(fourier) \n",
    "   print(manifold)\n",
    "   print(f'{prec:.3f} & {rec:.3f} & {f1:.3f} & {train_time:.2f}')\n",
    "   print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Initialize wandb and retrieve data\n",
    "api = wandb.Api()\n",
    "entity, project = 'eddiechen372', dataset \n",
    "runs = api.runs(f\"{entity}/{project}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/home/jupyter-iec_chau/miniconda3/envs/venv/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconst\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m    LORENTZ, \n\u001b[1;32m      4\u001b[0m    POINCARE, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m    ANTIVAX,\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer \n",
      "File \u001b[0;32m~/chau/Hyphen/trainer.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Metrics\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHyphen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoincare\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hyphen \u001b[38;5;28;01mas\u001b[39;00m PoincareHyphen\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHyphen\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meuclidean\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hyphen \u001b[38;5;28;01mas\u001b[39;00m EuclidHyphen\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mssm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SSM4RC \n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbert\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HBert \n",
      "File \u001b[0;32m~/chau/Hyphen/model/Hyphen/euclidean.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meuclidean\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CoAttention\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomenc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meuclidean_gcn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComEnc \n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpostenc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meuclidean_han\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PostEnc \n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhyp_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/chau/Hyphen/model/comenc/euclidean_gcn.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mComEnc\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     11\u001b[0m         in_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         device,\n\u001b[1;32m     15\u001b[0m     ):\n",
      "File \u001b[0;32m~/chau/Hyphen/model/utils/layers/layers.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessagePassing, SAGEConv\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_self_loops\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_scatter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scatter_add\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glorot, zeros, add_self_loops\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGraphConvolution\u001b[39;00m(Module):\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/site-packages/torch_scatter/__init__.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m spec \u001b[38;5;241m=\u001b[39m cuda_spec \u001b[38;5;129;01mor\u001b[39;00m cpu_spec\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBUILD_DOCS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibrary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mosp\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/site-packages/torch/_ops.py:1295\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1290\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m-> 1295\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[0;32m~/miniconda3/envs/venv/lib/python3.10/ctypes/__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: /home/jupyter-iec_chau/miniconda3/envs/venv/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from const import (\n",
    "   LORENTZ, \n",
    "   POINCARE, \n",
    "   EUCLID, \n",
    "   HAN, \n",
    "   HYPHEN, \n",
    "   HS4, \n",
    "   BERT,\n",
    "   TWITTER16,\n",
    "   TWITTER15, \n",
    "   PHEME,\n",
    "   POLITIFACT,\n",
    "   FIGLANG_TWITTER,\n",
    "   ANTIVAX,\n",
    ")\n",
    "from trainer import Trainer \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using manifold  euclid\n",
      "using fourier False\n",
      "using manifold  poincare\n",
      "using fourier False\n",
      "using manifold  euclid\n",
      "using fourier False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from const import (DATA_PATH)\n",
    "import pickle\n",
    "file = open(f'{DATA_PATH}/data/{dataset}/{dataset}_preprocessed.pkl', 'rb')\n",
    "df = pd.read_csv(f'data/{dataset}/{dataset}.csv') \n",
    "props = pickle.load(file)\n",
    "\n",
    "id_train, id_test = props['train']['id'], props['val']['id']\n",
    "raw_c_train, raw_c_val = list(df[df['id'].isin(id_train)]['comments']), list(df[df['id'].isin(id_test)]['comments'])\n",
    "raw_c_train = [c.split('::') if isinstance(c, str) else '' for c in raw_c_train]\n",
    "raw_c_val= [c.split('::') if isinstance(c, str) else '' for c in raw_c_val]\n",
    "x_train, x_val = props['train']['x'], props['val']['x']\n",
    "y_train, y_val = props['train']['y'], props['val']['y']\n",
    "c_train, c_val = props['train']['c'], props['val']['c']\n",
    "sub_train, sub_val = props['train']['subgraphs'], props['val']['subgraphs']\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' \n",
    "hs4_trainer = Trainer(\n",
    "    manifold=EUCLID,\n",
    "    model_type=HS4,\n",
    "    platform=TWITTER16, \n",
    "    max_sen_len=30, \n",
    "    max_com_len=30, \n",
    "    max_sents=20, \n",
    "    max_coms=20, \n",
    "    lr = 1e-3, \n",
    "    fourier = False,\n",
    "    curv=1.0,\n",
    "    enable_log=False,\n",
    "    embedding_dim=200\n",
    ")\n",
    "bert_trainer = Trainer(\n",
    "    manifold=POINCARE,\n",
    "    model_type=BERT,\n",
    "    platform=EUCLID, \n",
    "    max_sen_len=30, \n",
    "    max_com_len=30, \n",
    "    max_sents=20, \n",
    "    max_coms=20, \n",
    "    lr = 1e-3, \n",
    "    fourier = False,\n",
    "    curv=1.0,\n",
    "    enable_log=False,\n",
    "    embedding_dim=200\n",
    ")\n",
    "rnn_trainer = Trainer(\n",
    "    manifold=EUCLID,\n",
    "    model_type=HAN,\n",
    "    platform=TWITTER16, \n",
    "    max_sen_len=30, \n",
    "    max_com_len=30, \n",
    "    max_sents=20, \n",
    "    max_coms=20, \n",
    "    lr = 1e-3, \n",
    "    fourier = False,\n",
    "    curv=1.0,\n",
    "    enable_log=False,\n",
    "    embedding_dim=200\n",
    ")\n",
    "# hyphen_trainer = Trainer(\n",
    "#     manifold=EUCLID,\n",
    "#     model_type=HYPHEN,\n",
    "#     platform=TWITTER16, \n",
    "#     max_sen_len=30, \n",
    "#     max_com_len=30, \n",
    "#     max_sents=20, \n",
    "#     max_coms=20, \n",
    "#     lr = 1e-3, \n",
    "#     fourier = False,\n",
    "#     curv=1.0,\n",
    "#     enable_log=False,\n",
    "#     embedding_dim=200\n",
    "# )\n",
    "\n",
    "# hyphen_trainer.build_model(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved tokenizer\n",
      "Building model....\n",
      "building HypPostEnc\n",
      "building HypComEnc\n",
      "building CoAttention\n",
      "han built\n",
      "saved tokenizer\n",
      "Building model....\n",
      "building HypPostEnc\n",
      "building HypComEnc\n",
      "building CoAttention\n",
      "bert built\n",
      "saved tokenizer\n",
      "Building model....\n",
      "building HypPostEnc\n",
      "building HypComEnc\n",
      "building CoAttention\n",
      "hs4 built\n"
     ]
    }
   ],
   "source": [
    "rnn_trainer.build_model(32)\n",
    "bert_trainer.build_model(32)\n",
    "hs4_trainer.build_model(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters of HS4: 12604460\n",
      "Total parameters of dEFEND: 13188060\n",
      "Total parameters of MSA: 42212061\n",
      "Total parameters of BERT: 109482240\n",
      "Total parameters of RoBERTa: 124645632\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, RobertaModel\n",
    "models = {\n",
    "   'HS4': hs4_trainer.model,\n",
    "   'dEFEND': rnn_trainer.model,\n",
    "   'MSA': bert_trainer.model,\n",
    "   # 'Hyphen': hyphen_trainer.model,\n",
    "   'BERT': BertModel.from_pretrained('bert-base-uncased'),\n",
    "   'RoBERTa': RobertaModel.from_pretrained('roberta-base')\n",
    "   \n",
    "}\n",
    "for key in models.keys():\n",
    "   total_params = sum(p.numel() for p in models[key].parameters())\n",
    "   print(f\"Total parameters of {key}: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HS4', 'dEFEND', 'MSA', 'BERT', 'RoBERTa']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Create a figure with two subplots (vertically arranged)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m fig, (ax1, ax2, ax3) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())):\n\u001b[1;32m     33\u001b[0m     memory_footprints \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     34\u001b[0m     inference_times \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm \n",
    "from scipy.signal import savgol_filter\n",
    "import numpy as np\n",
    "\n",
    "def measure_memory_footprint(model, model_type:str, comment_input_size:torch.Tensor):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    # Measure memory before inference\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        if model_type == 'BERT' or model_type == 'RoBERTa':\n",
    "            input_tensor = torch.randint(0, 100, size=(comment_input_size[0],comment_input_size[1])).to(device)\n",
    "            model(input_tensor)\n",
    "        else:\n",
    "            input_tensor = torch.randint(0, 100, size=comment_input_size).to(device)\n",
    "            model(content=input_tensor, comment=input_tensor)\n",
    "        inference_time = time.time() - start \n",
    "    \n",
    "    # Measure memory after inference\n",
    "    memory_footprint = torch.cuda.max_memory_allocated(device) / (1024 ** 2)  # Convert to MB\n",
    "    return memory_footprint, inference_time\n",
    "\n",
    "sequence_lengths = range(5, 200, 5)\n",
    "\n",
    "# Create a figure with two subplots (vertically arranged)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "for i, key in enumerate(list(models.keys())):\n",
    "    memory_footprints = []\n",
    "    inference_times = []\n",
    "    no_sentence = []\n",
    "    for seq_len in tqdm(sequence_lengths):\n",
    "        \n",
    "        if key == 'BERT' or key == 'RoBERTa':\n",
    "            input_size = (32, seq_len*10)  # Example input size, adjust based on your model\n",
    "        else:\n",
    "            input_size = (32, seq_len, 10)  # Example input size, adjust based on your model\n",
    "        footprint, inference_time = measure_memory_footprint(models[key], key, input_size)\n",
    "        inference_times.append(inference_time)\n",
    "        memory_footprints.append(footprint)\n",
    "        no_sentence.append(seq_len)\n",
    "        if no_sentence[-1] > 49 and (key == 'BERT' or key == 'RoBERTa'): break\n",
    "\n",
    "    # Plot memory footprint on the first subplot\n",
    "    ax1.plot(no_sentence[1:], memory_footprints[1:], label=f'{key}', linestyle=('-' if key != 'HS4' else '-') )\n",
    "    # Plot inference time on the second subplot\n",
    "    ax2.plot(no_sentence[1:], inference_times[1:], label=f'{key}', linestyle=('-' if key != 'HS4' else '-') )\n",
    "    total_params = sum(p.numel() for p in models[key].parameters())/1e6\n",
    "    ax3.bar(key, total_params)\n",
    "\n",
    "# Set labels and titles for the first subplot\n",
    "ax1.set_xlabel('Number of sentences/comments')\n",
    "\n",
    "ax1.set_ylabel('Memory Footprint (MB)')\n",
    "# ax1.set_title('Memory Footprint vs. Sequence Length')\n",
    "ax1.grid(True)\n",
    "ax1.legend()\n",
    "\n",
    "# Set labels and titles for the second subplot\n",
    "ax2.set_xlabel('Number of sentences/comments')\n",
    "ax2.set_ylabel('Inference Time (Seconds)')\n",
    "# ax2.set_title('Inference Time vs. Sequence Length')\n",
    "ax2.grid(True)\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "ax3.grid(True)\n",
    "ax3.set_ylabel('Number of Parameters (Millions)')\n",
    "ax3.tick_params(axis='x', rotation=45) \n",
    "\n",
    "plt.tight_layout()  # Adjust layout to not overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# for run in tqdm(runs):\n",
    "#    run = api.run(f\"{entity}/{project}/{run.id}\")\n",
    "#    config = run.config\n",
    "#    history = run.scan_history(keys=['best F1', 'epoch'])\n",
    "#    type = config['type']\n",
    "#    manifold = config['manifold']\n",
    "#    for i,row in enumerate(history):\n",
    "#       row = pd.DataFrame({'type': [type], 'manifold': [manifold], 'epoch': [row['epoch']], 'best F1': [row['best F1']]})\n",
    "#       df = pd.concat([df, row])\n",
    "\n",
    "\n",
    "# df = df[df['type'] == 'hs4']\n",
    "# sns.set_theme(style=\"darkgrid\")\n",
    "# sns.lineplot(data=df, x=\"epoch\", y=\"best F1\", hue=\"manifold\", style=\"manifold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
